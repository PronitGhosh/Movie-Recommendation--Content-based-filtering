{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3aefae-b450-46b0-8413-1dc246888d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imdb import IMDb\n",
    "from imdb._exceptions import IMDbError\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d73b4-d131-4070-93fa-c292057e4679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5_file(file_path,dataset_name='similarity_matrix3'):\n",
    "    with h5py.File(file_path,'r')as f:\n",
    "        data=f[dataset_name][:]\n",
    "    return data\n",
    "file_path='similarity_matrix3.h5'\n",
    "similarity_matrix=read_hdf5_file(file_path)\n",
    "similarity_matrix=pd.DataFrame(similarity_matrix)\n",
    "similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b481bc-a77c-4cf1-9cf5-be4b80d4abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362795a6-6f9f-498e-9299-ca48c58aa1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(row):\n",
    "    top_indices = row.nlargest(21).index  # Get the indices of the top 21 values\n",
    "    result = pd.Series(np.nan, index=row.index)  # Initialize a Series with NaN\n",
    "    result[top_indices] = row[top_indices]  # Assign the top 21 values to their original positions\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8234b99-9fcf-41ae-9ad4-de39d3ead24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(similarity_matrix, batch_size=1000, output_file='similarity_preprocess5.h5'):\n",
    "    num_samples = similarity_matrix.shape[0]\n",
    "    \n",
    "    with h5py.File(output_file, 'w') as f:\n",
    "        # Create an empty dataset in HDF5 to store the processed results\n",
    "        dset = f.create_dataset(\n",
    "            \"similarity_preprocess5\",\n",
    "            shape=(num_samples, similarity_matrix.shape[1]),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            # Get the current batch of rows from similarity_matrix\n",
    "            batch = similarity_matrix.iloc[i:i+batch_size]\n",
    "            \n",
    "            # Apply the 'evaluate' function to each row in the batch\n",
    "            batch_result = batch.apply(lambda x: evaluate(x), axis=1)\n",
    "\n",
    "            \n",
    "            # Fill the HDF5 dataset with the processed batch\n",
    "            dset[i:i+batch_size, :] = batch_result.values\n",
    "            \n",
    "            print(f\"Processed batch {i} to {i+batch_size}\")\n",
    "\n",
    "    print(f\"Data successfully saved to {output_file}\")\n",
    "compute(similarity_matrix, batch_size=1000, output_file='similarity_preprocess5.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941bbbd8-abd6-42c0-98c0-b90dd985a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7aa5e-c1ee-4035-8cc0-c20fb169bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67abaed-2fdb-425c-858b-af3f4492311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c845466-abcf-4f8d-a76c-a8bd2ac58ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6f8ad-7f8d-4f04-8ed4-bb558d20bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(value,col_idx):\n",
    "    return col_idx if not pd.isna(value) else value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5fe2b-ba2a-4146-b5d8-c7bbcc9a257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_similarity_matrix_chunks(similarity_matrix, chunk_size):\n",
    "    \"\"\"\n",
    "    Process a large similarity matrix in chunks for the custom cal function.\n",
    "    \"\"\"\n",
    "    n_rows = similarity_matrix.shape[0]\n",
    "    processed_chunks = []\n",
    "\n",
    "    for start_row in range(0, n_rows, chunk_size):\n",
    "        end_row = min(start_row + chunk_size, n_rows)\n",
    "        chunk = similarity_matrix.iloc[start_row:end_row]\n",
    "        \n",
    "        # Apply the transformation for each row in the chunk\n",
    "        processed_chunk = chunk.apply(\n",
    "            lambda row: [cal(val, idx) for idx, val in enumerate(row)], axis=1\n",
    "        )\n",
    "        \n",
    "        processed_chunks.append(processed_chunk)\n",
    "        print(f\"Processed rows {start_row} to {end_row-1}\")\n",
    "\n",
    "    # Combine all processed chunks into the final DataFrame\n",
    "    result = pd.concat(processed_chunks, axis=0)\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# Assuming similarity_matrix is your large DataFrame\n",
    "chunk_size = 1000  # Adjust based on memory capacity\n",
    "similarity_matrix1 = process_similarity_matrix_chunks(similarity_matrix, chunk_size)\n",
    "\n",
    "# Now similarity_matrix_processed contains the final result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af80db-cde9-45a0-b9c9-a2c14f5bca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f906a-97fb-4329-83bf-a50fe228c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4c172-96cd-4b75-af36-bbbbd0f1ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix= pd.DataFrame(similarity_matrix1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de8554-2b64-4fd4-a1da-c820a999f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af329bee-722b-4888-91ca-c7eacd24cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = similarity_matrix.apply(lambda row: pd.Series([x for x in row if not pd.isna(x)] + [np.nan] * row.isna().sum()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479c767-ad6d-4491-9ab8-4b2947752815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f447f-9e60-465a-9196-9ab1b207973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_sorted.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ea0d9-1064-4e1b-a5da-d40698023e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd8f43-cc98-4066-b50e-c91ffab83f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbd8e6-7203-405a-8964-65b02879b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('movie-name_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd010dc4-9842-4da8-8da9-098fb5338155",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.read_csv('movies-with_posters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345bf7b-8c58-42f3-8c5d-5ef24ca7c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb9e27-2315-49fd-a083-896193d3bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732082c3-30b3-4104-bcaa-b04bc910c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abf08c-43fc-45e7-8860-6f0a026f4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean movie names\n",
    "def clean_movie_name(name):\n",
    "    # Remove special characters and convert to lowercase\n",
    "    name = re.sub(r'[^a-zA-Z0-9\\s]', '', name).lower()\n",
    "    # Split the name into words and remove stop words\n",
    "    name = ' '.join(word for word in name.split() if word not in stop_words)\n",
    "    # Remove spaces to make it a continuous string\n",
    "    return name.replace(\" \", \"\")\n",
    "\n",
    "# Apply the cleaning function to the movie_name column\n",
    "df['movie_name'] = df['movie_name'].apply(clean_movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2be4b-cc29-4974-8d00-a8e56ea504bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068397d-d048-4d8a-a5a0-a62dc4d52edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ant-Man and the Wasp: Quantumania\n",
    "#Spider-Man\n",
    "#The Exorcist\n",
    "#Avatar\n",
    "#Avatar: The Way of Water\n",
    "#RRR\n",
    "#The Red Pearl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4319377a-2b3c-43ee-a85e-f3fe8d97fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_name=\"avatar\"\n",
    "movie_name=clean_movie_name(movie_name)\n",
    "print(\"The movie name entered :\",movie_name)\n",
    "row_index=df.index[df['movie_name']==movie_name][0]\n",
    "print(row_index)\n",
    "list1= df_cleaned.iloc[row_index].tolist()\n",
    "print(list1)\n",
    "print(\"Top 20 recommended Movies : \")\n",
    "for i in list1 :\n",
    "    if i!=row_index:\n",
    "      print(new_df.loc[i,'movie_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee4e34-f158-4c9d-a144-68fe22840d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc8ce9-151d-480f-940d-6dd01357a317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
